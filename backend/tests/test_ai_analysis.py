#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIåˆ†æåŠŸèƒ½æµ‹è¯•
éªŒè¯å„ç§LLMæä¾›å•†çš„åˆ†æåŠŸèƒ½
"""

import sys
import os
import time
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app import create_app
from app.services.ai.analysis_service import AnalysisService
from app.services.ai.llm_provider import LLMProvider

def test_ai_analysis():
    """æµ‹è¯•AIåˆ†æåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•AIåˆ†æåŠŸèƒ½...")
    
    app = create_app()
    with app.app_context():
        from app import db
        analysis_service = AnalysisService(db.session)
        
        # æµ‹è¯•è‚¡ç¥¨ä¿¡æ¯
        test_stock = {
            'code': 'AAPL',
            'name': 'è‹¹æœå…¬å¸',
            'market': 'US',
            'industry': 'ç§‘æŠ€'
        }
        
        print(f"\nğŸ“Š æµ‹è¯•è‚¡ç¥¨: {test_stock['code']} - {test_stock['name']}")
        
        # æµ‹è¯•æ‰€æœ‰å¯ç”¨çš„LLMæä¾›å•†
        providers = ['gemini', 'qwen', 'deepseek', 'chatgpt']
        
        for provider_name in providers:
            print(f"\nğŸ” æµ‹è¯• {provider_name.upper()}...")
            
            try:
                # æµ‹è¯•è¿æ¥
                print(f"  ğŸ”— æµ‹è¯•è¿æ¥...")
                provider = LLMProvider(provider_name)
                
                if not provider.is_available():
                    print(f"  âŒ {provider_name.upper()} ä¸å¯ç”¨")
                    continue
                
                print(f"  âœ… {provider_name.upper()} è¿æ¥æˆåŠŸ")
                
                # æµ‹è¯•ç®€å•åˆ†æ
                print(f"  ğŸ“ æµ‹è¯•ç®€å•åˆ†æ...")
                start_time = time.time()
                
                prompt = f"è¯·ç®€è¦ä»‹ç»ä¸€ä¸‹{test_stock['name']}ï¼ˆ{test_stock['code']}ï¼‰è¿™å®¶å…¬å¸ã€‚"
                response = provider.analyze(prompt)
                
                end_time = time.time()
                response_time = end_time - start_time
                
                if response and response.strip():
                    print(f"  âœ… {provider_name.upper()} åˆ†ææˆåŠŸ")
                    print(f"  ğŸ“Š å“åº”æ—¶é—´: {response_time:.2f}ç§’")
                    print(f"  ğŸ¯ ä½¿ç”¨æ¨¡å‹: {provider.get_model_name()}")
                    
                    # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
                    preview = response[:200] + "..." if len(response) > 200 else response
                    print(f"  ğŸ“ å†…å®¹é¢„è§ˆ: {preview}")
                else:
                    print(f"  âŒ {provider_name.upper()} åˆ†æå¤±è´¥: æ— å“åº”")
                    
            except Exception as e:
                print(f"  âŒ {provider_name.upper()} æµ‹è¯•å¼‚å¸¸: {str(e)}")
        
        # æµ‹è¯•åˆ†ææœåŠ¡
        print(f"\nğŸ§ª æµ‹è¯•åˆ†ææœåŠ¡...")
        print(f"ğŸ“‹ é»˜è®¤AIæä¾›å•†: gemini")
        
        # æµ‹è¯•æç¤ºè¯
        try:
            prompts = analysis_service._get_analysis_prompt()
            print(f"  - é»˜è®¤æç¤ºè¯: {len(prompts)} å­—ç¬¦")
        except Exception as e:
            print(f"  - æç¤ºè¯è·å–å¤±è´¥: {e}")
        
        print(f"\nğŸ‰ AIåˆ†æåŠŸèƒ½æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_ai_analysis()
