#!/usr/bin/env python3
"""
æµ‹è¯•æ‰€æœ‰LLMæä¾›å•†
"""
import os
import sys
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app import create_app, db
from app.services.ai.llm_provider import LLMProviderFactory

def test_all_providers():
    """æµ‹è¯•æ‰€æœ‰LLMæä¾›å•†"""
    print("ğŸ§ª æµ‹è¯•æ‰€æœ‰LLMæä¾›å•†...")
    
    app = create_app()
    
    with app.app_context():
        # è·å–å¯ç”¨çš„æä¾›å•†
        providers = LLMProviderFactory.get_available_providers()
        print(f"\nğŸ“‹ å¯ç”¨æä¾›å•†: {', '.join(providers)}")
        
        # æµ‹è¯•æ¯ä¸ªæä¾›å•†
        for provider_type in providers:
            print(f"\nğŸ” æµ‹è¯• {provider_type.upper()}...")
            
            # è·å–é…ç½®
            if provider_type == 'gemini':
                config = {
                    'name': 'gemini',
                    'api_key': app.config.get('GEMINI_API_KEY'),
                    'model': app.config.get('GEMINI_MODEL', 'gemini-2.0-flash'),
                    'max_tokens': 100,
                    'temperature': 0.7
                }
            elif provider_type == 'chatgpt':
                config = {
                    'name': 'chatgpt',
                    'api_key': app.config.get('OPENAI_API_KEY'),
                    'model': app.config.get('OPENAI_MODEL', 'gpt-3.5-turbo'),
                    'max_tokens': 100,
                    'temperature': 0.7
                }
            elif provider_type == 'qwen':
                config = {
                    'name': 'qwen',
                    'api_key': app.config.get('QWEN_API_KEY'),
                    'model': app.config.get('QWEN_MODEL', 'qwen-turbo'),
                    'max_tokens': 100,
                    'temperature': 0.7
                }
            elif provider_type == 'deepseek':
                config = {
                    'name': 'deepseek',
                    'api_key': app.config.get('DEEPSEEK_API_KEY'),
                    'model': app.config.get('DEEPSEEK_MODEL', 'deepseek-chat'),
                    'max_tokens': 100,
                    'temperature': 0.7
                }
            else:
                print(f"âŒ æœªçŸ¥æä¾›å•†: {provider_type}")
                continue
            
            # æ£€æŸ¥APIå¯†é’¥
            if not config['api_key']:
                print(f"âš ï¸  {provider_type.upper()} APIå¯†é’¥æœªé…ç½®")
                continue
            
            try:
                # åˆ›å»ºæä¾›å•†å®ä¾‹
                provider = LLMProviderFactory.create_provider(provider_type, config)
                
                # æµ‹è¯•è¿æ¥
                print(f"  ğŸ”— æµ‹è¯•è¿æ¥...")
                if provider.test_connection():
                    print(f"  âœ… {provider_type.upper()} è¿æ¥æˆåŠŸ")
                    
                    # æµ‹è¯•ç®€å•åˆ†æ
                    print(f"  ğŸ“ æµ‹è¯•ç®€å•åˆ†æ...")
                    stock_info = {
                        'code': 'AAPL',
                        'name': 'è‹¹æœå…¬å¸',
                        'market': 'US',
                        'industry': 'æ¶ˆè´¹ç”µå­',
                        'exchange': 'NASDAQ',
                        'analysis_date': '2025-01-01'
                    }
                    
                    result = provider.generate_analysis("è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ ${name} å…¬å¸", stock_info)
                    
                    if result['success']:
                        print(f"  âœ… {provider_type.upper()} åˆ†ææˆåŠŸ")
                        print(f"  ğŸ“Š å“åº”æ—¶é—´: {result.get('response_time', 0):.2f}ç§’")
                        print(f"  ğŸ¯ ä½¿ç”¨æ¨¡å‹: {result.get('model', 'unknown')}")
                        print(f"  ğŸ“ å†…å®¹é¢„è§ˆ: {result['content'][:100]}...")
                    else:
                        print(f"  âŒ {provider_type.upper()} åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                else:
                    print(f"  âŒ {provider_type.upper()} è¿æ¥å¤±è´¥")
                    
            except Exception as e:
                print(f"  âŒ {provider_type.upper()} æµ‹è¯•å¼‚å¸¸: {str(e)}")
        
        print("\nğŸ‰ æ‰€æœ‰LLMæä¾›å•†æµ‹è¯•å®Œæˆï¼")

def test_analysis_service():
    """æµ‹è¯•åˆ†ææœåŠ¡"""
    print("\nğŸ§ª æµ‹è¯•åˆ†ææœåŠ¡...")
    
    app = create_app()
    
    with app.app_context():
        from app.services.ai.analysis_service import AnalysisService
        
        service = AnalysisService(db.session)
        
        # è·å–é»˜è®¤æä¾›å•†
        default_provider = app.config.get('DEFAULT_AI_PROVIDER', 'gemini')
        print(f"ğŸ“‹ é»˜è®¤AIæä¾›å•†: {default_provider}")
        
        # æµ‹è¯•æç¤ºè¯
        print("\nğŸ“ æµ‹è¯•æç¤ºè¯:")
        for prompt_type in ['default', 'fundamental', 'technical']:
            prompt = service._get_analysis_prompt(prompt_type)
            print(f"  - {prompt_type}: {len(prompt)} å­—ç¬¦")

if __name__ == "__main__":
    test_all_providers()
    test_analysis_service()
