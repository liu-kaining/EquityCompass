#!/usr/bin/env python3
"""
æµ‹è¯•è¯¦ç»†åˆ†ææŠ¥å‘Š
"""

import os
import sys
import json
from datetime import datetime

def load_env():
    """åŠ è½½ç¯å¢ƒå˜é‡"""
    env_file = '../.env'
    if os.path.exists(env_file):
        with open(env_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key] = value

def test_detailed_analysis():
    """æµ‹è¯•è¯¦ç»†åˆ†ææŠ¥å‘Š"""
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_env()
    
    api_key = os.getenv('QWEN_API_KEY')
    if not api_key:
        print("âŒ è¯·è®¾ç½® QWEN_API_KEY ç¯å¢ƒå˜é‡")
        return False
    
    print(f"ğŸ”‘ APIå¯†é’¥: {api_key[:10]}...")
    
    try:
        import dashscope
        from dashscope import Generation
        
        # è®¾ç½®API Key
        dashscope.api_key = api_key
        
        print(f"\nğŸ§ª æµ‹è¯•è¯¦ç»†åˆ†ææŠ¥å‘Š")
        
        # å‡†å¤‡è¯·æ±‚
        research_prompt = """ä½ æ˜¯ä¸€ä½é¡¶çº§çš„è‚¡ç¥¨åˆ†æå¸ˆï¼Œæ‹¥æœ‰20å¹´ä»¥ä¸Šçš„æŠ•èµ„ç»éªŒã€‚è¯·å¯¹è‚¡ç¥¨ è‹¹æœå…¬å¸ (AAPL) è¿›è¡Œæå…¶æ·±å…¥ã€è¯¦ç»†ã€ä¸“ä¸šçš„æŠ•èµ„åˆ†æã€‚

è¦æ±‚ï¼š
1. æŠ¥å‘Šå¿…é¡»éå¸¸è¯¦ç»†ï¼Œè‡³å°‘3000-5000å­—
2. åŒ…å«å¤§é‡å…·ä½“æ•°æ®ã€å›¾è¡¨åˆ†æå’Œä¸“ä¸šæœ¯è¯­
3. ä»å¤šä¸ªç»´åº¦è¿›è¡Œå…¨é¢åˆ†æï¼šåŸºæœ¬é¢ã€æŠ€æœ¯é¢ã€è¡Œä¸šåˆ†æã€é£é™©è¯„ä¼°ç­‰
4. æä¾›å…·ä½“çš„æŠ•èµ„å»ºè®®å’Œæ“ä½œç­–ç•¥
5. ä½¿ç”¨ä¸“ä¸šçš„é‡‘èåˆ†ææ¡†æ¶å’Œæ–¹æ³•è®º
6. åŒ…å«å®šé‡åˆ†æå’Œå®šæ€§åˆ†æ
7. æä¾›é£é™©æç¤ºå’Œå…è´£å£°æ˜

è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯è¿›è¡Œæ·±å…¥åˆ†æï¼š
è¯·å¯¹è‹¹æœå…¬å¸(AAPL)è¿›è¡Œå…¨é¢çš„åŸºæœ¬é¢åˆ†æï¼ŒåŒ…æ‹¬å…¬å¸æ¦‚å†µã€è´¢åŠ¡åˆ†æã€è¡Œä¸šåˆ†æã€é£é™©è¯„ä¼°å’ŒæŠ•èµ„å»ºè®®ã€‚

è¯·ç”Ÿæˆä¸€ä»½æœºæ„çº§åˆ«çš„ä¸“ä¸šæŠ•èµ„åˆ†ææŠ¥å‘Šã€‚"""
        
        api_params = {
            'model': 'qwen-deep-research',
            'messages': [{'role': 'user', 'content': research_prompt}],
            'stream': True,  # qwen-deep-research ç›®å‰ä»…æ”¯æŒæµå¼è¾“å‡º
            'parameters': {
                'max_tokens': 15000,  # å¤§å¹…å¢åŠ tokené™åˆ¶ï¼Œç¡®ä¿ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
                'temperature': 0.7
            }
        }
        
        print(f"ğŸ“¤ å‘é€è¯¦ç»†åˆ†æè¯·æ±‚")
        print(f"ğŸ“‹ æç¤ºè¯é•¿åº¦: {len(research_prompt)} å­—ç¬¦")
        print(f"ğŸ”§ max_tokens: 15000")
        
        # è°ƒç”¨æµå¼API
        responses = Generation.call(**api_params)
        
        current_phase = None
        phase_content = ""
        final_content = ""
        research_goal = ""
        web_sites = []
        
        print(f"ğŸ“¥ å¼€å§‹æ¥æ”¶æµå¼å“åº”...")
        
        for response in responses:
            # æ£€æŸ¥å“åº”çŠ¶æ€ç 
            if hasattr(response, 'status_code') and response.status_code != 200:
                print(f"âŒ HTTPè¿”å›ç ï¼š{response.status_code}")
                if hasattr(response, 'code'):
                    print(f"é”™è¯¯ç ï¼š{response.code}")
                if hasattr(response, 'message'):
                    print(f"é”™è¯¯ä¿¡æ¯ï¼š{response.message}")
                continue
            
            if hasattr(response, 'output') and response.output:
                message = response.output.get('message', {})
                phase = message.get('phase')
                content = message.get('content', '')
                status = message.get('status')
                extra = message.get('extra', {})
                
                # é˜¶æ®µå˜åŒ–æ£€æµ‹
                if phase != current_phase:
                    if current_phase and phase_content:
                        print(f"âœ… {current_phase} é˜¶æ®µå®Œæˆ")
                    current_phase = phase
                    phase_content = ""
                    print(f"ğŸ”„ è¿›å…¥ {phase} é˜¶æ®µ")
                
                # ç´¯ç§¯é˜¶æ®µå†…å®¹
                if content:
                    phase_content += content
                    final_content += content
                    print(f"ğŸ“ å†…å®¹æ›´æ–°: {len(content)} å­—ç¬¦ (ç´¯è®¡: {len(final_content)} å­—ç¬¦)")
                
                # å¤„ç†WebResearché˜¶æ®µçš„ç‰¹æ®Šä¿¡æ¯
                if phase == "WebResearch":
                    if extra.get('deep_research', {}).get('research'):
                        research_info = extra['deep_research']['research']
                        
                        # å¤„ç†streamingQueriesçŠ¶æ€
                        if status == "streamingQueries":
                            if 'researchGoal' in research_info:
                                goal = research_info['researchGoal']
                                if goal and goal != research_goal:
                                    research_goal = goal
                                    print(f"ğŸ¯ ç ”ç©¶ç›®æ ‡: {goal}")
                        
                        # å¤„ç†streamingWebResultçŠ¶æ€
                        elif status == "streamingWebResult":
                            if 'webSites' in research_info:
                                sites = research_info['webSites']
                                if sites and len(sites) > len(web_sites):
                                    web_sites = sites
                                    print(f"ğŸŒ å‘ç° {len(sites)} ä¸ªç½‘ç«™")
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if status == "finished" and phase == "answer":
                    print(f"âœ… æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
                    break
        
        # å¦‚æœæ²¡æœ‰è·å–åˆ°å†…å®¹ï¼Œä½¿ç”¨é˜¶æ®µå†…å®¹
        if not final_content and phase_content:
            final_content = phase_content
        
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"   æœ€ç»ˆå†…å®¹é•¿åº¦: {len(final_content)} å­—ç¬¦")
        print(f"   å†…å®¹é•¿åº¦æ˜¯å¦ç¬¦åˆè¦æ±‚: {'âœ… æ˜¯' if len(final_content) >= 3000 else 'âŒ å¦'}")
        if final_content:
            print(f"   å†…å®¹é¢„è§ˆ: {final_content[:300]}...")
        if research_goal:
            print(f"   ç ”ç©¶ç›®æ ‡: {research_goal}")
        if web_sites:
            print(f"   æœç´¢ç½‘ç«™æ•°: {len(web_sites)}")
        
        # åˆ†æå†…å®¹è´¨é‡
        if final_content:
            word_count = len(final_content.split())
            print(f"   å­—æ•°ç»Ÿè®¡: {word_count} å­—")
            print(f"   å¹³å‡æ¯å­—å­—ç¬¦æ•°: {len(final_content)/word_count:.2f}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸“ä¸šæœ¯è¯­
            professional_terms = ['å¸‚ç›ˆç‡', 'å¸‚å‡€ç‡', 'ROE', 'ROA', 'æ¯›åˆ©ç‡', 'å‡€åˆ©ç‡', 'ç°é‡‘æµ', 'ä¼°å€¼', 'é£é™©', 'æŠ•èµ„å»ºè®®']
            found_terms = [term for term in professional_terms if term in final_content]
            print(f"   åŒ…å«ä¸“ä¸šæœ¯è¯­: {found_terms}")
            print(f"   ä¸“ä¸šæœ¯è¯­è¦†ç›–ç‡: {len(found_terms)}/{len(professional_terms)} ({len(found_terms)/len(professional_terms)*100:.1f}%)")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å‡ºé”™: {str(e)}")
        return False

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯•è¯¦ç»†åˆ†ææŠ¥å‘Š...")
    success = test_detailed_analysis()
    
    if success:
        print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼")
        sys.exit(1)
